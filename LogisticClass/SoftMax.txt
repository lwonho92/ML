import tensorflow as tf
import numpy as np
# cross entropy

xy = np.loadtxt('train2.txt', unpack=True, dtype='float32')
x_data = np.transpose(xy[0:3])
y_data = np.transpose(xy[3:])

X = tf.placeholder("float", [None, 3])  # 1, x1, x2 (bias)
Y = tf.placeholder("float", [None, 3])  #   A, B, C (classes)

W = tf.Variable(tf.zeros([3, 3]))

# H(X) =
# S(y_i) = e^y_i / sigma( e^y_i )
# D(S, L) = - L_i * log( s_i )
h = tf.matmul(X, W)
hypothesis = tf.nn.softmax(h)

# cost(W) = - sigma( L_i * log( S_i ) )
cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), reduction_indices=1))

# W := W - alpha * cost'(W)
# new_W = old_W - alpha * cost'(old_W)

a = tf.Variable(0.001)
optimizer = tf.train.GradientDescentOptimizer(a)
train = optimizer.minimize(cost)

init = tf.initialize_all_variables()

sess = tf.Session()
sess.run(init)

for step in xrange(2001):
    sess.run(train, feed_dict={X:x_data, Y:y_data})
    if step % 20 == 0:
        print step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W)

a = sess.run(hypothesis, feed_dict={X:[[1, 11, 7]]})
print a, sess.run(tf.arg_max(a, 1))

b = sess.run(hypothesis, feed_dict={X:[[1, 3, 4]]})
print b, sess.run(tf.arg_max(b, 1))

c = sess.run(hypothesis, feed_dict={X:[[1, 1, 0]]})
print c, sess.run(tf.arg_max(c, 1))

all = sess.run(hypothesis, feed_dict={X:[[1, 11, 7], [1, 3, 4], [1, 1, 0]]})
print all, sess.run(tf.arg_max(all, 1))

# ds(x) / dx = s(x) * (1 - s(x))
# d / dx * log(x) = log(e) / x

# log'(hypothesis) = hypothesis` * log(e) / hypothesis = s(x) * (1 - s(x)) * log(e) / s(x)
# log'(1 - hypothesis) = - hypothesis` * log(e) / (1 - hypothesis) = - s(x) * (1 - s(x)) * log(e) / (1 - s(x))

# cost' = ( -1 / m ) * sigma'( y * log( H(x) ) + (1 - y) * log( 1 - H(x) ) )
#       = ( -1 / m ) * sigma( y * log'( H(x) ) + (1 - y) * log'( 1 - H(x) ) )
#       = ( -1 / m ) * sigma( y * ( s(x) * (1 - s(x)) * log(e) / s(x) ) + (1 - y) * ( - s(x) * (1 - s(x)) * log(e) / (1 - s(x)) ) )